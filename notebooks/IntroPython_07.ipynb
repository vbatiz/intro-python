{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKWXreTj95Z6"
      },
      "source": [
        "# Complejidad de los datos\n",
        "\n",
        "### Introducci√≥n\n",
        "\n",
        "En esta sesi√≥n analizaremos el tema de complejidad de los datos y algunas t√©cnicas para tratar los efectos de la misma. Este cuaderno se basa parcialmente en el material del curso de limpieza de datos de Kaggle disponible [aqu√≠](https://www.kaggle.com/learn/data-cleaning)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8qKe50s95Z-"
      },
      "source": [
        "### Gesti√≥n de valores omitidos\n",
        "Elimine los valores que faltan o rell√©nelos con un flujo de trabajo automatizado.\n",
        "\n",
        "La limpieza de datos es una parte clave de la ciencia de datos, pero puede ser muy frustrante. ¬øPor qu√© hay campos de texto ilegibles? ¬øQu√© hacer con los valores que faltan? ¬øPor qu√© las fechas no tienen el formato correcto? ¬øC√≥mo puede solucionar r√°pidamente la introducci√≥n de datos incoherentes? En este tema, aprender√° por qu√© se ha encontrado con estos problemas y, lo que es m√°s importante, c√≥mo solucionarlos.\n",
        "\n",
        "En este cuaderno, aprender√° a abordar algunos de los problemas m√°s comunes de limpieza de datos para que pueda analizar sus datos m√°s r√°pidamente. Realizar√° cinco ejercicios pr√°cticos con datos reales y desordenados y responder√° a algunas de las preguntas m√°s frecuentes sobre la limpieza de datos.\n",
        "\n",
        "En este cuaderno, veremos c√≥mo tratar los valores faltantes u omitidos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bySSHnJZ95Z-"
      },
      "source": [
        "#### Primer vistazo a los datos\n",
        "\n",
        "Lo primero que tenemos que hacer es cargar las bibliotecas y el conjunto de datos que vamos a utilizar.\n",
        "\n",
        "Para la demostraci√≥n, utilizaremos un conjunto de datos de eventos ocurridos en partidos de f√∫tbol americano. Debido al tama√±o del conjunto de datos, lo descargaremos y posteriormente lo cargaremos a nuestro espacio temporal. [Ir a la p√°gina de descarga](https://www.kaggle.com/code/alexisbcook/handling-missing-values/data?select=NFL+Play+by+Play+2009-2017+%28v4%29.csv)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOMBSNG095Z_",
        "outputId": "4d6bd9f6-3029-4cf4-9381-164958c6442c"
      },
      "outputs": [],
      "source": [
        "# m√≥dulos que usaremos\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# cargamos los datos\n",
        "nfl_data = pd.read_csv(\"NFL Play by Play 2009-2017 (v4).csv\")\n",
        "\n",
        "# fijamos la semilla para reproducibilidad\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEI_X99_95aA"
      },
      "source": [
        "Lo primero que hay que hacer cuando se recibe un nuevo conjunto de datos es echar un vistazo a algunos de ellos. Esto nos permite ver que todo se lee correctamente y nos da una idea de lo que est√° pasando con los datos. En este caso, vamos a ver si hay valores perdidos u omitidos, que son representados en Python con `NaN`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "ILNIu14E95aA",
        "outputId": "8be11832-50fc-400b-94b9-1fa8fec620ab"
      },
      "outputs": [],
      "source": [
        "nfl_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_W6oH2695aB"
      },
      "source": [
        "¬øObservamos datos faltantes?\n",
        "\n",
        "¬øCu√°ntos puntos de datos faltantes tenemos?\n",
        "\n",
        "Bien, ahora sabemos que tenemos algunos valores faltantes. Veamos cu√°ntos tenemos en cada columna."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DrU9z_795aB",
        "outputId": "45b3c008-7475-4724-9ed9-e63a32bc7606"
      },
      "outputs": [],
      "source": [
        "# obtenemos el n√∫mero de datos faltantes por columna\n",
        "missing_values_count = nfl_data.isnull().sum()\n",
        "\n",
        "# Revisamos el n√∫mero de datos faltantes en las primeras 10 columnas del conjunto de datos (tiene 102 columnas en total).\n",
        "missing_values_count[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pVqW_Qr95aC"
      },
      "source": [
        "¬øQu√© opinas de los resultados mostrados? Ser√≠a √∫til saber qu√© porcentaje de valores faltan en nuestro conjunto de datos para hacernos una idea m√°s precisa de la magnitud del problema:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gACtEoRaOguR",
        "outputId": "9b8e94cf-f429-4b54-e169-35ac6bad254e"
      },
      "outputs": [],
      "source": [
        "print(nfl_data.shape)\n",
        "a,b = nfl_data.shape\n",
        "print(a)\n",
        "print(b)\n",
        "print(a*b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5EXLnNs95aC",
        "outputId": "0b005414-9fa0-40f0-e559-9e2cffc6d87e"
      },
      "outputs": [],
      "source": [
        "# ¬øCu√°ntos valores faltantes tenemos en total en el conjunto datos?\n",
        "print(nfl_data.shape)\n",
        "total_cells = np.product(nfl_data.shape)\n",
        "total_missing = missing_values_count.sum()\n",
        "\n",
        "# porcentaje de datos faltante\n",
        "percent_missing = (total_missing/total_cells) * 100\n",
        "print(f'Celdas totales: {total_cells:,}')   # Se agrega :, a la derecha de la variable para dar formato de miles\n",
        "print(f'Celdas con datos faltantes: {total_missing:,}') # Se agrega :, a la derecha de la variable para dar formato de miles\n",
        "print(f'Porcentaje de datos faltantes: {round(percent_missing,2)}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWLqWpQ995aC"
      },
      "source": [
        "¬øQu√© opinas del porcentaje de datos faltantes?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGtzGiAz95aD"
      },
      "source": [
        "#### Averiguar por qu√© faltan datos\n",
        "\n",
        "Este es el punto en el que entramos en la parte de la ciencia de datos que solemos llamar \"intuici√≥n de datos\", es decir, \"analizar realmente los datos e intentar averiguar por qu√© son como son y c√≥mo afectar√°n a nuestro an√°lisis\". Puede ser una parte frustrante de la ciencia de datos, especialmente si eres nuevo en este campo y no tienes mucha experiencia. Para tratar los valores que faltan, tendr√°s que usar tu intuici√≥n para averiguar por qu√© falta el valor. Una de las preguntas m√°s importantes que puede hacerse para averiguarlo es la siguiente:\n",
        "\n",
        "**¬øEste valor falta porque no se registr√≥ o porque no existe?**\n",
        "\n",
        "Si falta un valor porque no existe (como la altura del hijo mayor de alguien que no tiene hijos), no tiene sentido intentar adivinar cu√°l podr√≠a ser. Estos valores probablemente quieras mantenerlos como NaN. Por otro lado, si falta un valor porque no se registr√≥, puede intentar adivinar cu√°l podr√≠a haber sido bas√°ndose en los dem√°s valores de esa columna y fila. Esto se llama imputaci√≥n, ¬°y aprenderemos a hacerlo a continuaci√≥n! :)\n",
        "\n",
        "Veamos un ejemplo. Observando el n√∫mero de valores faltantes en el marco de datos nfl_data, nos damos cuenta de que la columna \"TimeSecs\" tiene muchos valores faltantes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPBHFJTf95aD",
        "outputId": "acb9e667-0977-432f-f05e-25413fa0384a"
      },
      "outputs": [],
      "source": [
        "# Revisamos el n√∫mero de datos faltantes en las primeras 10 columnas del conjunto de datos (tiene 102 columnas en total).\n",
        "missing_values_count[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR_eAYIh95aD"
      },
      "source": [
        "Revisando la documentaci√≥n, podemos ver que esta columna tiene informaci√≥n sobre el n√∫mero de segundos que quedaban en el partido cuando se hizo la jugada. Esto significa que estos valores probablemente faltan porque no se registraron, y no porque no existan. Por lo tanto, tendr√≠a sentido que intent√°ramos adivinar cu√°les deber√≠an ser en lugar de dejarlos como `NaN`.\n",
        "\n",
        "Por otra parte, hay otros campos, como \"PenalizedTeam\", en los que tambi√©n faltan muchos campos. En este caso, sin embargo, el campo falta porque si no hubo penalizaci√≥n no tiene sentido decir qu√© equipo fue penalizado. Para esta columna, tendr√≠a m√°s sentido dejarla vac√≠a o a√±adir un tercer valor como \"ninguno\" y utilizarlo para reemplazar los `NaN`.\n",
        "\n",
        "Si est√° realizando un an√°lisis de datos muy cuidadoso, este es el punto en el que mirar√≠a cada columna individualmente para averiguar cu√°l es la mejor estrategia para rellenar los valores que faltan. En el resto de este cuaderno, trataremos algunas t√©cnicas \"r√°pidas y sucias\" que pueden ayudarle con los valores que faltan, pero que probablemente acabar√°n eliminando informaci√≥n √∫til o a√±adiendo ruido a los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8bNN-dA95aD"
      },
      "source": [
        "#### Eliminar valores faltantes\n",
        "Si tiene prisa o no tiene motivos para averiguar por qu√© faltan valores, una opci√≥n es eliminar las filas o columnas que contengan valores que falten. (Nota: ¬°generalmente no se recomienda este enfoque para proyectos importantes! Suele merecer la pena tomarse el tiempo necesario para revisar los datos y examinar una por una todas las columnas con valores faltantes para conocer realmente el conjunto de datos).\n",
        "\n",
        "Si est√° seguro de que quiere eliminar las filas con valores faltantes, pandas tiene una funci√≥n muy √∫til, dropna() para ayudarle a hacerlo. Vamos a probarla en nuestro conjunto de datos de la NFL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "id": "aCC-LbXn95aD",
        "outputId": "3530f173-a45e-4a24-8ac4-282239c38f05"
      },
      "outputs": [],
      "source": [
        "# eliminar todos los renglones que contengan un valor faltante u omitido\n",
        "nfl_data.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU52YwaO95aD"
      },
      "source": [
        "¬øQu√© sucedi√≥? ¬°parece que se han eliminado todos nuestros datos! üò± Esto se debe a que cada fila de nuestro conjunto de datos ten√≠a al menos un valor faltante. Podr√≠amos tener mejor suerte eliminando todas las columnas que tienen al menos un valor faltante en su lugar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "MTSMg6Oh95aE",
        "outputId": "28fde50b-4da4-4707-d2c4-d705437f4281"
      },
      "outputs": [],
      "source": [
        "# Eliminemos ahora todas las columnas en donde exista un valor faltante\n",
        "columns_with_na_dropped = nfl_data.dropna(axis=1) #Al agregar el par√°metro axis=1 estamos indicando que el criterio sea revisar columnas. Por defecto se revisan renglones (axis=0)\n",
        "columns_with_na_dropped.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-F9Zx2fy95aE",
        "outputId": "78cde983-37d2-4c2d-f1b9-a82c2c3d376d"
      },
      "outputs": [],
      "source": [
        "columns_with_na_dropped.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDbH8ctBTFuM",
        "outputId": "d859dd22-6a64-491f-c226-b44e930a566d"
      },
      "outputs": [],
      "source": [
        "#a, b = nfl_data.shape\n",
        "a = nfl_data.shape[0]\n",
        "b = nfl_data.shape[1]\n",
        "print(a)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbmwdhos95aE"
      },
      "source": [
        "Calcular cuanta informaci√≥n hemos perdido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6gO59CL95aE",
        "outputId": "91d408be-1f67-4a10-88c9-d3b030d32ec8"
      },
      "outputs": [],
      "source": [
        "print(f\"Columnas en el conjunto de datos original: {nfl_data.shape[1]}\")\n",
        "print(f\"Columnas restantes tras eliminar datos faltantes: {columns_with_na_dropped.shape[1]}\")\n",
        "print(f\"Total de columnas eliminadas: {nfl_data.shape[1] - columns_with_na_dropped.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoL3EIta95aE"
      },
      "source": [
        "#### Rellenar autom√°ticamente los valores que faltan\n",
        "Otra opci√≥n es intentar rellenar los valores que faltan. Para ello, vamos a tomar una peque√±a subsecci√≥n de los datos de la NFL para que se imprima bien."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "_BMKzKX_95aF",
        "outputId": "5639d070-ece2-4a87-cb99-4dae3a7cf68b"
      },
      "outputs": [],
      "source": [
        "# obtenemos un peque√±o subconjunto del conjunto de datos de la NFL\n",
        "subset_nfl_data = nfl_data.loc[:, 'EPA':'Season'].head()\n",
        "subset_nfl_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14Jw-Jfa95aF"
      },
      "source": [
        "Podemos utilizar la funci√≥n fillna() de Panda para que rellene por nosotros los valores que faltan en un marco de datos. Una opci√≥n que tenemos es especificar con qu√© queremos que se sustituyan los valores NaN. Aqu√≠, estoy diciendo que me gustar√≠a reemplazar todos los valores NaN con 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "S2Hbb2AS95aF",
        "outputId": "017d3638-ba64-4579-f108-9800201709db"
      },
      "outputs": [],
      "source": [
        "# remplazar todos los datos NaN con 0\n",
        "subset_nfl_data.fillna(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_D13Epg95aF"
      },
      "source": [
        "Quiz√°s una mejor estrategia sea sustituir los valores que faltan por cualquier valor que le siga directamente en la misma columna. (Esto tiene mucho sentido para conjuntos de datos en los que las observaciones tienen alg√∫n tipo de orden l√≥gico)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "Eb6YJfNg95aF",
        "outputId": "bed43cc5-1fac-44bc-9e4c-73698bb84008"
      },
      "outputs": [],
      "source": [
        "# reemplazar todos los NaN con el valor que viene directamente despu√©s de √©l en la misma columna\n",
        "# y sustituir todos los NaN restantes por 0\n",
        "subset_nfl_data.fillna(method='bfill', axis=0).fillna(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXpxJVHB95aF"
      },
      "source": [
        "Opciones para el par√°metro `method`:\n",
        "\n",
        "**ffill**\n",
        "\n",
        "Rellenar valores propagando la √∫ltima observaci√≥n v√°lida a la siguiente v√°lida.\n",
        "\n",
        "**bfill**\n",
        "\n",
        "Rellenar valores utilizando la siguiente observaci√≥n v√°lida para rellenar el hueco."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "2YeFf_XYVjPr",
        "outputId": "93390419-f384-44bf-d11d-82ce3ac3cd5f"
      },
      "outputs": [],
      "source": [
        "# reemplazar todos los NaN con el valor que viene directamente antes de √©l en la misma columna\n",
        "# y sustituir todos los NaN restantes por 0\n",
        "subset_nfl_data.fillna(method='ffill', axis=0).fillna(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7QsTC8M95aF"
      },
      "source": [
        "### Escalado y Normalizaci√≥n\n",
        "Transformar variables num√©ricas para que tengan propiedades √∫tiles.\n",
        "\n",
        "#### Cargamos los m√≥dulos a utilizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvoJILGl95aF",
        "outputId": "bf9a7e3b-ef35-4dbe-f51a-6a0624eb528b"
      },
      "outputs": [],
      "source": [
        "%pip install mlxtend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-apKtOUV95aG"
      },
      "outputs": [],
      "source": [
        "# m√≥dulos a utilizar\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# para transformaci√≥n Box-Cox\n",
        "from scipy import stats\n",
        "\n",
        "# para escalado min_max\n",
        "from mlxtend.preprocessing import minmax_scaling\n",
        "\n",
        "# m√≥dulos de visualizaci√≥n\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# fijamos la semilla para reproducibilidad\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcTUe-d095aG"
      },
      "source": [
        "#### Escalado frente a normalizaci√≥n: ¬øCu√°l es la diferencia?\n",
        "\n",
        "Una de las razones por las que es f√°cil confundirse entre escalado y normalizaci√≥n es porque los t√©rminos a veces se utilizan indistintamente y, para hacerlo a√∫n m√°s confuso, ¬°son muy similares! En ambos casos, se transforman los valores de las variables num√©ricas para que los puntos de datos transformados tengan propiedades √∫tiles espec√≠ficas. La diferencia es que en el escalado, se cambia el rango de los datos, mientras que en la normalizaci√≥n, cambia la forma de la distribuci√≥n de los datos.\n",
        "\n",
        "Hablemos un poco m√°s en profundidad de cada una de estas opciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_34rZS195aG"
      },
      "source": [
        "#### Escalado\n",
        "\n",
        "Esto significa que est√° transformando sus datos para que se ajusten a una escala espec√≠fica, como 0-100 o 0-1. Es conveniente escalar los datos cuando se utilizan m√©todos basados en medidas de la distancia entre los puntos de datos, como las m√°quinas de vectores de soporte (SVM) o los vecinos m√°s cercanos (KNN). Con estos algoritmos, un cambio de \"1\" en cualquier caracter√≠stica num√©rica recibe la misma importancia.\n",
        "\n",
        "Por ejemplo, puede consultar los precios de algunos productos en yenes y en d√≥lares estadounidenses. Un d√≥lar estadounidense vale unos 100 yenes, pero si no escala los precios, m√©todos como SVM o KNN considerar√°n que una diferencia de precio de 1 yen es tan importante como una diferencia de 1 d√≥lar estadounidense. Est√° claro que esto no encaja con nuestras intuiciones del mundo. Con la divisa, puedes convertir entre divisas. Pero, ¬øqu√© ocurre con la altura y el peso? No est√° del todo claro cu√°ntas libras equivalen a una pulgada (o cu√°ntos kilogramos equivalen a un metro).\n",
        "\n",
        "Al escalar las variables, puedes comparar diferentes variables en igualdad de condiciones. Para ayudarte a entender c√≥mo es el escalado, veamos un ejemplo inventado. (No te preocupes, en el siguiente ejercicio trabajaremos con datos reales)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "SnuPh2SE95aG",
        "outputId": "c11b5f75-211c-4c24-ac8f-a38900a29ad0"
      },
      "outputs": [],
      "source": [
        "# generar 1000 puntos de datos extra√≠dos aleatoriamente de una distribuci√≥n exponencial\n",
        "original_data = np.random.exponential(size=1000)\n",
        "\n",
        "# mix-max escala los datos entre 0 y 1\n",
        "scaled_data = minmax_scaling(original_data, columns=[0])\n",
        "\n",
        "# graficamos ambos para comparar\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15, 3))\n",
        "sns.histplot(original_data, ax=ax[0], kde=True, legend=False)\n",
        "ax[0].set_title(\"Datos Originales\")\n",
        "sns.histplot(scaled_data, ax=ax[1], kde=True, legend=False)\n",
        "ax[1].set_title(\"Datos Escalados\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIN8liZR95aG"
      },
      "source": [
        "Observe que la forma de los datos no cambia, pero que en lugar de ir de 0 a 8, ahora van de 0 a 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK7oeRww95aG"
      },
      "source": [
        "#### Normalizaci√≥n\n",
        "El escalado s√≥lo cambia el rango de los datos. La normalizaci√≥n es una transformaci√≥n m√°s radical. El objetivo de la normalizaci√≥n es cambiar las observaciones para que puedan describirse como una distribuci√≥n normal.\n",
        "\n",
        "[Distribuci√≥n normal](https://es.wikipedia.org/wiki/Distribuci%C3%B3n_normal): Tambi√©n conocida como \"curva de campana\", es una distribuci√≥n estad√≠stica espec√≠fica en la que aproximadamente el mismo n√∫mero de observaciones se sit√∫an por encima y por debajo de la media, la media y la mediana son iguales y hay m√°s observaciones cerca de la media. La distribuci√≥n normal tambi√©n se conoce como distribuci√≥n de Gauss.\n",
        "\n",
        "En general, normalizar√° sus datos si va a utilizar una t√©cnica de aprendizaje autom√°tico o estad√≠stica que asuma que sus datos se distribuyen normalmente. Algunos ejemplos son el an√°lisis discriminante lineal (LDA) y el Bayes ingenuo gaussiano. (Consejo profesional: cualquier m√©todo con \"gaussiano\" en el nombre probablemente asume la normalidad).\n",
        "\n",
        "El m√©todo que estamos utilizando para normalizar aqu√≠ se llama Transformaci√≥n [Box-Cox](https://en.wikipedia.org/wiki/Power_transform#Box%E2%80%93Cox_transformation). Echemos un vistazo r√°pido a c√≥mo se ve la normalizaci√≥n de algunos datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "nPk0p5VN95aG",
        "outputId": "da48ea57-5b2d-4000-8d4c-d4dbd79f711c"
      },
      "outputs": [],
      "source": [
        "# normalizar los datos exponenciales con boxcox\n",
        "normalized_data = stats.boxcox(original_data)\n",
        "\n",
        "# graficamos ambos para comparar\n",
        "fig, ax=plt.subplots(1, 2, figsize=(15, 3))\n",
        "sns.histplot(original_data, ax=ax[0], kde=True, legend=False)\n",
        "ax[0].set_title(\"Datos Originales\")\n",
        "sns.histplot(normalized_data[0], ax=ax[1], kde=True, legend=False)\n",
        "ax[1].set_title(\"Datos Normalizados\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DXNyKjD95aH"
      },
      "source": [
        "Observe que la forma de nuestros datos ha cambiado. Antes de la normalizaci√≥n ten√≠an casi forma de L. Pero despu√©s de la normalizaci√≥n se parecen m√°s al contorno de una campana (de ah√≠ lo de \"curva de campana\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### An√°lisis de fechas\n",
        "Ayuda a Python a reconocer fechas compuestas por d√≠a, mes y a√±o.\n",
        "\n",
        "#### Cargamos los m√≥dulos y conjunto de datos a utilizar\n",
        "Trabajaremos con un conjunto de datos que contiene informaci√≥n sobre los desprendimientos de tierra ocurridos entre 2007 y 2016."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# m√≥dulos a utilizar\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "\n",
        "# cargamos los datos\n",
        "landslides = pd.read_csv(\"data/landslides.csv\")\n",
        "\n",
        "# fijamos la semilla para reproducibilidad\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Comprobar el tipo de datos de nuestra columna de fecha\n",
        "Empezaremos echando un vistazo a las cinco primeras filas de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "landslides.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Estaremos trabajando con la columna \"date\". Revisemos que realmente contenga fechas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imprimir los primeros renglones de la columna \"date\"\n",
        "print(landslides['date'].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Al ver los datos podemos asumir como humanos que son datos de fechas, pero esto no significa que Python reconozca que son fechas. Si revisamos la √∫ltima l√≠nea de la funci√≥n head() notamos que el tipo de dato (dtype) es \"object\".\n",
        "\n",
        "Si revisamos la documentaci√≥n de dtype de pandas, veremos que tambi√©n hay un dtype espec√≠fico datetime64. Como el dtype de nuestra columna es object y no datetime64, podemos decir que Python no sabe que esta columna contiene fechas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tambi√©n podemos ver s√≥lo el dtype de una columna sin imprimir las primeras filas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Podemos revisar el tipo de dato de una columna\n",
        "landslides['date'].dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\"O\" es el c√≥digo de \"objeto\", por lo que podemos ver que estos dos m√©todos nos dan la misma informaci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tambi√©n podemos revisar los tipos de dato de todas las columnas\n",
        "landslides.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Convertir nuestras columnas de fecha a datetime\n",
        "Ahora que sabemos que nuestra columna de fecha no est√° siendo reconocida como una fecha, es hora de convertirla para que sea reconocida como una fecha. Esto se llama \"analizar fechas\" (\"parsing dates\" en ingl√©s) porque estamos tomando una cadena e identificando las partes que la componen.\n",
        "\n",
        "Podemos determinar cu√°l es el formato de nuestras fechas con una gu√≠a llamada \"directiva strftime\", de la que puedes encontrar m√°s informaci√≥n [aqu√≠](https://strftime.org/)]. La idea b√°sica es que hay que se√±alar donde est√°n las diferentes partes de la fecha y qu√© signos de puntuaci√≥n hay entre ellas. Hay muchas partes posibles de una fecha, pero las m√°s comunes son %d para el d√≠a, %m para el mes, %y para un a√±o de dos d√≠gitos y %Y para un a√±o de cuatro d√≠gitos.\n",
        "\n",
        "Algunos ejemplos:\n",
        "\n",
        "- 1/17/07 tiene el formato \"%m/%d/%y\".\n",
        "- 17-1-2007 tiene el formato \"%d-%m-%Y\".\n",
        "\n",
        "Si volvemos a mirar la cabecera de la columna \"date\" (fecha) en el conjunto de datos de desprendimientos, vemos que tiene el formato \"month/day/two-digit year\" (mes/d√≠a/a√±o de dos d√≠gitos), por lo que podemos utilizar la misma sintaxis que en el primer ejemplo para analizar las fechas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# crear una nueva columna, date_parsed, con las fechas analizadas\n",
        "landslides['date_parsed'] = pd.to_datetime(landslides['date'], format=\"%m/%d/%y\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# revisamos los primeros datos\n",
        "landslides['date_parsed'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora que nuestras fechas est√°n correctamente analizadas, podemos interactuar con ellas de forma √∫til.\n",
        "\n",
        "¬øQu√© pasa si nos encontramos con un error con m√∫ltiples formatos de fecha? Mientras estamos especificando el formato de fecha, a veces se encontrar√° con un error cuando hay m√∫ltiples formatos de fecha en una sola columna. Si eso ocurre, puede hacer que pandas intente deducir cu√°l deber√≠a ser el formato de fecha correcto. Puede hacerlo as√≠:\n",
        "\n",
        "`landslides['date_parsed'] = pd.to_datetime(landslides['Date'], infer_datetime_format=True)`\n",
        "\n",
        "¬øPor qu√© no utilizar siempre infer_datetime_format = True? Hay dos grandes razones para no hacer que pandas adivine siempre el formato de hora. La primera es que pandas no siempre ser√° capaz de averiguar el formato de fecha correcto, especialmente si alguien se ha puesto creativo con la entrada de datos. La segunda es que es mucho m√°s lento que especificar el formato exacto de las fechas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Seleccionar el d√≠a del mes\n",
        "Ahora que tenemos una columna de fechas analizadas, podemos extraer informaci√≥n como el d√≠a del mes en que se produjo un desprendimiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# obtener e√± d√≠a del mes de la columna date_parsed\n",
        "day_of_month_landslides = landslides['date_parsed'].dt.day\n",
        "day_of_month_landslides.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "¬øQu√© sucede si intentamos hacer lo mismo con la columna \"date\" original?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "day_lanslides = landslides['date'].dt.day"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Trazar el d√≠a del mes para comprobar el an√°lisis sint√°ctico de la fecha\n",
        "Uno de los mayores peligros al analizar fechas es confundir los meses y los d√≠as. La funci√≥n to_datetime() tiene mensajes de error muy √∫tiles, pero no est√° de m√°s volver a comprobar que los d√≠as del mes que hemos extra√≠do tienen sentido.\n",
        "\n",
        "Para ello, vamos a trazar un histograma de los d√≠as del mes. Esperamos que tenga valores entre 1 y 31 (Con un asterisco en el 31 porque no todos los meses tienen 31 d√≠as) y, puesto que no hay raz√≥n para suponer que los desprendimientos son m√°s frecuentes en unos d√≠as del mes que en otros, esperamos una distribuci√≥n relativamente uniforme. Veamos si es as√≠:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remover valores nulos (NaN)\n",
        "day_of_month_landslides = day_of_month_landslides.dropna()\n",
        "\n",
        "# graficamos el d√≠a del mes\n",
        "sns.displot(day_of_month_landslides, kde=False, bins=31) #KDE (kernel density estimate) representa los datos mediante una curva de densidad de probabilidad continua en una o varias dimensiones.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
